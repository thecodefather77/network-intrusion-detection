{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f585cbe1-c0d8-4f6b-a45f-5a7cf82a67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89ff60b-72ad-4a5d-99cd-3551f603ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(r\"D:\\Analytixlabs\\Internship\\Project 4\\Cyber Security\\output\\train_multi_data.parquet\")\n",
    "test = pd.read_parquet(r\"D:\\Analytixlabs\\Internship\\Project 4\\Cyber Security\\output\\test_multi_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75126521-e01b-4f20-af57-ff3ec6741ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_type = train['attack_type']\n",
    "y_test_type = test['attack_type']\n",
    "Xtrain = train.drop(columns = ['attack_type', 'label'])\n",
    "Xtest = test.drop(columns = ['attack_type', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a5fdc-0b88-44c2-b172-4213350dd60b",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58719cc0-79bf-4706-9124-4b9e8508e30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attack_type\n",
       "dos_ddos        0.755910\n",
       "portscan        0.213042\n",
       "brute_force     0.024920\n",
       "bot             0.004455\n",
       "web_attack      0.001563\n",
       "infiltration    0.000081\n",
       "heartbleed      0.000030\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_type).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d669657-afb2-4a1f-ba1e-ca18a63d4b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "attack_type\n",
       "dos_ddos        225348\n",
       "portscan         63511\n",
       "brute_force       7429\n",
       "bot               1328\n",
       "web_attack         466\n",
       "infiltration        24\n",
       "heartbleed           9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3028f5-5a6f-403f-81b8-082268039f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_type = np.where(test['attack_type'].isin(['infiltration', 'heartbleed']), 'others', test['attack_type'])\n",
    "y_train_type = np.where(train['attack_type'].isin(['infiltration', 'heartbleed']), 'others', train['attack_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e93ce1-057e-4ad8-955f-147f9fe9c7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos_ddos       0.755910\n",
       "portscan       0.213042\n",
       "brute_force    0.024920\n",
       "bot            0.004455\n",
       "web_attack     0.001563\n",
       "others         0.000111\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_type).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe646888-bca1-4273-aa21-1e12f4938b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos_ddos       96416\n",
       "portscan       27308\n",
       "brute_force     3193\n",
       "bot              625\n",
       "web_attack       207\n",
       "others            14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test_type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07c8352f-b927-418a-8173-0cfe2793bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict = {\n",
    "    'brute_force': 20000,\n",
    "    'bot': 5000,\n",
    "    'web_attack': 3000,\n",
    "    'others': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35e6ff0f-5052-4711-abc3-fdd345501165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SCL\\anaconda3\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:370: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(\n",
    "    k_neighbors = 5,\n",
    "    sampling_strategy = y_dict,\n",
    "    n_jobs = -1,\n",
    "    random_state = 43\n",
    ")\n",
    "\n",
    "Xtrain_os, ytrain_os = smote.fit_resample(Xtrain, y_train_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1745b8e4-b23c-47f8-998d-102b84eda2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317859, 77)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_os.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09a3accb-3355-4cf0-9af8-e7f76a4dde9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dos_ddos       0.708956\n",
       "portscan       0.199809\n",
       "brute_force    0.062921\n",
       "bot            0.015730\n",
       "web_attack     0.009438\n",
       "others         0.003146\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ytrain_os).value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f0df1d0-7200-497a-b695-2a47a69d57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "ytrain_encoded = encoder.fit_transform(ytrain_os)\n",
    "ytest_encoded = encoder.transform(y_test_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aea057a5-a10a-4326-a3f2-7e90c669c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     10000\n",
      "           1       0.99      0.90      0.94     20000\n",
      "           2       1.00      1.00      1.00    225348\n",
      "           3       1.00      1.00      1.00      5000\n",
      "           4       1.00      1.00      1.00     63511\n",
      "           5       0.80      0.97      0.88      8000\n",
      "\n",
      "    accuracy                           0.99    331859\n",
      "   macro avg       0.96      0.98      0.97    331859\n",
      "weighted avg       0.99      0.99      0.99    331859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       1.00      0.89      0.94      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       1.00      0.86      0.92        14\n",
      "           4       1.00      1.00      1.00     27308\n",
      "           5       0.35      0.93      0.51       207\n",
      "\n",
      "    accuracy                           1.00    127763\n",
      "   macro avg       0.89      0.94      0.89    127763\n",
      "weighted avg       1.00      1.00      1.00    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.02,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d702d8d4-03d6-44a8-b302-7c68c7cd891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"gamma\": [0, 0.05, 0.1, 0.2],\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"n_estimators\": [50, 100, 200, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab7cf19c-ff12-443d-80e1-f4f0dd1417e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  28.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  27.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=7, n_estimators=300, subsample=0.6; total time=  21.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=7, n_estimators=300, subsample=0.6; total time=  21.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=7, n_estimators=300, subsample=0.6; total time=  21.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   7.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.9; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.6; total time=  10.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.6; total time=  10.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.6; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.6; total time=  18.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.6; total time=  18.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.6; total time=  18.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  25.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  25.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.8; total time=  25.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   8.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.8; total time=  24.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.8; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.05, max_depth=4, min_child_weight=5, n_estimators=300, subsample=0.8; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  23.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  22.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  23.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  21.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  21.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.02, max_depth=3, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  21.2s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.6; total time=  27.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.6; total time=  26.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=3, n_estimators=300, subsample=0.6; total time=  27.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=  22.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=  21.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.9; total time=  24.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.9; total time=  27.1s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.9; total time=  28.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=3, n_estimators=300, subsample=0.9; total time=  26.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8; total time=  16.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8; total time=  16.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8; total time=  17.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7; total time=  15.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.01, max_depth=6, min_child_weight=1, n_estimators=200, subsample=0.7; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=1, n_estimators=100, subsample=0.7; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.9; total time=  21.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.9; total time=  21.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.05, learning_rate=0.1, max_depth=3, min_child_weight=3, n_estimators=300, subsample=0.9; total time=  22.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=7, n_estimators=100, subsample=0.7; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=7, n_estimators=100, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=7, n_estimators=100, subsample=0.7; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7; total time=  22.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7; total time=  23.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.01, max_depth=5, min_child_weight=5, n_estimators=300, subsample=0.7; total time=  22.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.9; total time=  19.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.9; total time=  19.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.9; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.9; total time=  23.6s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.9; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.9; total time=  23.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, subsample=0.6; total time=   9.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, subsample=0.6; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.02, max_depth=4, min_child_weight=7, n_estimators=100, subsample=0.6; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.6; total time=  29.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.6; total time=  21.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=300, subsample=0.6; total time=  22.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=200, subsample=0.9; total time=  17.3s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=200, subsample=0.9; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=200, subsample=0.9; total time=  16.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.02, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.02, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   7.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.02, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   8.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.02, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.6; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.02, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.6; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0, learning_rate=0.02, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.6; total time=   7.3s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.6; total time=  24.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.6; total time=  25.5s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=1, n_estimators=300, subsample=0.6; total time=  24.4s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   6.9s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.02, max_depth=3, min_child_weight=5, n_estimators=100, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  21.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  20.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.8; total time=  20.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.02, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.02, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.02, max_depth=4, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   9.7s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.7; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.9; total time=  16.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.9; total time=  17.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.05, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.9; total time=  18.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.9; total time=  24.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.9; total time=  24.3s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.05, max_depth=4, min_child_weight=1, n_estimators=300, subsample=0.9; total time=  23.5s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.9; total time=  23.2s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.9; total time=  24.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=7, n_estimators=300, subsample=0.9; total time=  23.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   8.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   7.6s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.05, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=100, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=7, n_estimators=300, subsample=0.7; total time=  24.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=7, n_estimators=300, subsample=0.7; total time=  23.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0, learning_rate=0.01, max_depth=6, min_child_weight=7, n_estimators=300, subsample=0.7; total time=  25.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=300, subsample=0.8; total time=  21.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=300, subsample=0.8; total time=  21.9s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=7, n_estimators=300, subsample=0.8; total time=  24.6s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7; total time=  20.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.2, learning_rate=0.1, max_depth=5, min_child_weight=5, n_estimators=200, subsample=0.7; total time=  19.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   8.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=  10.2s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=  10.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.1, learning_rate=0.02, max_depth=6, min_child_weight=5, n_estimators=100, subsample=0.9; total time=   8.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.8; total time=  14.6s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.8; total time=  14.0s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=200, subsample=0.8; total time=  13.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.9; total time=  19.1s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.9; total time=  18.4s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.05, max_depth=5, min_child_weight=3, n_estimators=200, subsample=0.9; total time=  16.5s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=6, min_child_weight=7, n_estimators=200, subsample=0.6; total time=  17.7s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=6, min_child_weight=7, n_estimators=200, subsample=0.6; total time=  18.0s\n",
      "[CV] END colsample_bytree=0.6, gamma=0.05, learning_rate=0.1, max_depth=6, min_child_weight=7, n_estimators=200, subsample=0.6; total time=  17.8s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8; total time=  15.9s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8; total time=  16.0s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=4, min_child_weight=3, n_estimators=200, subsample=0.8; total time=  15.0s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.6; total time=  17.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.6; total time=  16.9s\n",
      "[CV] END colsample_bytree=0.7, gamma=0, learning_rate=0.05, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.6; total time=  16.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.05, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=100, subsample=0.8; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=  14.8s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=  14.1s\n",
      "[CV] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=1, n_estimators=200, subsample=0.8; total time=  14.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=200, subsample=0.6; total time=  15.4s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=200, subsample=0.6; total time=  15.7s\n",
      "[CV] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.02, max_depth=5, min_child_weight=7, n_estimators=200, subsample=0.6; total time=  14.7s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.7; total time=  13.5s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.7; total time=  14.2s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.01, max_depth=3, min_child_weight=3, n_estimators=200, subsample=0.7; total time=  13.2s\n",
      "Best Params: {'subsample': 0.9, 'n_estimators': 300, 'min_child_weight': 7, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.8}\n",
      "Best Score: 0.9772403550888216\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring=\"f1_macro\",   # important for multiclass imbalance\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "print(\"Best Params:\", random_search.best_params_)\n",
    "print(\"Best Score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b93dac16-8dae-40b7-9f4a-686c31a384ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2000\n",
      "           1       0.99      0.90      0.94     20000\n",
      "           2       1.00      1.00      1.00    225348\n",
      "           3       1.00      0.99      0.99      1000\n",
      "           4       1.00      1.00      1.00     63511\n",
      "           5       0.80      0.94      0.86      8000\n",
      "\n",
      "    accuracy                           0.99    319859\n",
      "   macro avg       0.96      0.97      0.97    319859\n",
      "weighted avg       0.99      0.99      0.99    319859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       0.99      0.89      0.94      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       0.92      0.86      0.89        14\n",
      "           4       1.00      1.00      1.00     27308\n",
      "           5       0.35      0.89      0.51       207\n",
      "\n",
      "    accuracy                           1.00    127763\n",
      "   macro avg       0.88      0.94      0.89    127763\n",
      "weighted avg       1.00      1.00      1.00    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=7,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daa0d9fd-bb87-45b6-8867-8bd53e5a16da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2000\n",
      "           1       1.00      0.88      0.94     20000\n",
      "           2       1.00      1.00      1.00    225348\n",
      "           3       1.00      0.98      0.99      1000\n",
      "           4       1.00      1.00      1.00     63511\n",
      "           5       0.77      0.95      0.85      8000\n",
      "\n",
      "    accuracy                           0.99    319859\n",
      "   macro avg       0.96      0.97      0.96    319859\n",
      "weighted avg       0.99      0.99      0.99    319859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       1.00      0.87      0.93      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       0.92      0.86      0.89        14\n",
      "           4       1.00      1.00      1.00     27308\n",
      "           5       0.32      0.93      0.48       207\n",
      "\n",
      "    accuracy                           1.00    127763\n",
      "   macro avg       0.87      0.94      0.88    127763\n",
      "weighted avg       1.00      1.00      1.00    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=7,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a4f4823-8581-4873-95b0-5af597e94d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2000\n",
      "           1       1.00      0.88      0.94     20000\n",
      "           2       1.00      1.00      1.00    225348\n",
      "           3       1.00      0.98      0.99      1000\n",
      "           4       1.00      1.00      1.00     63511\n",
      "           5       0.77      0.95      0.85      8000\n",
      "\n",
      "    accuracy                           0.99    319859\n",
      "   macro avg       0.96      0.97      0.96    319859\n",
      "weighted avg       0.99      0.99      0.99    319859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       1.00      0.87      0.93      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       0.92      0.86      0.89        14\n",
      "           4       1.00      1.00      1.00     27308\n",
      "           5       0.32      0.93      0.48       207\n",
      "\n",
      "    accuracy                           1.00    127763\n",
      "   macro avg       0.87      0.94      0.88    127763\n",
      "weighted avg       1.00      1.00      1.00    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=7,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5faa136-f4e1-4054-a42a-9a367d17b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       0.98      0.93      0.95     20000\n",
      "           2       1.00      1.00      1.00    225348\n",
      "           3       1.00      1.00      1.00      1000\n",
      "           4       1.00      1.00      1.00     63511\n",
      "           5       0.65      0.84      0.73      3000\n",
      "\n",
      "    accuracy                           0.99    317859\n",
      "   macro avg       0.94      0.96      0.95    317859\n",
      "weighted avg       0.99      0.99      0.99    317859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       0.99      0.91      0.95      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       0.92      0.86      0.89        14\n",
      "           4       1.00      1.00      1.00     27308\n",
      "           5       0.40      0.80      0.53       207\n",
      "\n",
      "    accuracy                           1.00    127763\n",
      "   macro avg       0.88      0.93      0.89    127763\n",
      "weighted avg       1.00      1.00      1.00    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=400,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=7,\n",
    "    gamma=0.2,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bfe6fa8-2b33-412f-bfc3-f4a46777ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       0.98      0.92      0.95     20000\n",
      "           2       1.00      1.00      1.00    225348\n",
      "           3       1.00      0.98      0.99      1000\n",
      "           4       1.00      1.00      1.00     63511\n",
      "           5       0.62      0.79      0.70      3000\n",
      "\n",
      "    accuracy                           0.99    317859\n",
      "   macro avg       0.93      0.95      0.94    317859\n",
      "weighted avg       0.99      0.99      0.99    317859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       0.98      0.91      0.94      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       1.00      0.86      0.92        14\n",
      "           4       1.00      1.00      1.00     27308\n",
      "           5       0.38      0.75      0.50       207\n",
      "\n",
      "    accuracy                           1.00    127763\n",
      "   macro avg       0.89      0.92      0.89    127763\n",
      "weighted avg       1.00      1.00      1.00    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=400,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    min_child_weight=7,\n",
    "    gamma=0.5,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=1.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff0e70cd-1318-40f0-936d-451c59c67568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       0.98      0.87      0.92     20000\n",
      "           2       0.99      1.00      1.00    225348\n",
      "           3       1.00      0.91      0.95      1000\n",
      "           4       1.00      0.99      0.99     63511\n",
      "           5       0.54      0.89      0.67      3000\n",
      "\n",
      "    accuracy                           0.99    317859\n",
      "   macro avg       0.92      0.94      0.92    317859\n",
      "weighted avg       0.99      0.99      0.99    317859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       0.95      0.85      0.90      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       1.00      0.79      0.88        14\n",
      "           4       1.00      0.99      0.99     27308\n",
      "           5       0.32      0.89      0.48       207\n",
      "\n",
      "    accuracy                           0.99    127763\n",
      "   macro avg       0.88      0.92      0.87    127763\n",
      "weighted avg       1.00      0.99      0.99    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=300,\n",
    "    max_depth=2,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.5,\n",
    "    colsample_bylevel = 0.5,\n",
    "    min_child_weight=10,\n",
    "    gamma=1.0,\n",
    "    reg_alpha=0.5,\n",
    "    reg_lambda=2.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2299e373-522e-4f40-931c-52d06a8c4b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5000\n",
      "           1       0.98      0.92      0.95     20000\n",
      "           2       1.00      1.00      1.00    225348\n",
      "           3       1.00      0.92      0.96      1000\n",
      "           4       1.00      1.00      1.00     63511\n",
      "           5       0.62      0.80      0.70      3000\n",
      "\n",
      "    accuracy                           0.99    317859\n",
      "   macro avg       0.93      0.94      0.93    317859\n",
      "weighted avg       0.99      0.99      0.99    317859\n",
      "\n",
      "Test Data Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       625\n",
      "           1       0.98      0.90      0.94      3193\n",
      "           2       1.00      1.00      1.00     96416\n",
      "           3       1.00      0.86      0.92        14\n",
      "           4       1.00      1.00      1.00     27308\n",
      "           5       0.37      0.76      0.50       207\n",
      "\n",
      "    accuracy                           1.00    127763\n",
      "   macro avg       0.89      0.92      0.89    127763\n",
      "weighted avg       1.00      1.00      1.00    127763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=6,\n",
    "    n_estimators=250,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.6,\n",
    "    colsample_bytree=0.6,\n",
    "    min_child_weight=20,\n",
    "    gamma=2.0,\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=2.0,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Fitting to the Pipeline\n",
    "xgb_model.fit(Xtrain_os, ytrain_encoded)\n",
    "\n",
    "# Predicting the target\n",
    "ytrain_pred = xgb_model.predict(Xtrain_os)\n",
    "ytest_pred = xgb_model.predict(Xtest)\n",
    "\n",
    "#Train Test Data Performance\n",
    "print('Train Data Performance:')\n",
    "print(metrics.classification_report(ytrain_encoded, ytrain_pred))\n",
    "print('Test Data Performance:')\n",
    "print(metrics.classification_report(ytest_encoded, ytest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dabce6c5-13f4-406a-a793-56c74997890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Analytixlabs\\\\Internship\\\\Project 4\\\\Cyber Security\\\\output\\\\multiclass_model.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(xgb_model, r\"D:\\Analytixlabs\\Internship\\Project 4\\Cyber Security\\output\\multiclass_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d21ae4b9-3c01-4d50-bdf4-497e027c6d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Analytixlabs\\\\Internship\\\\Project 4\\\\Cyber Security\\\\output\\\\label_encoder.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(encoder, r\"D:\\Analytixlabs\\Internship\\Project 4\\Cyber Security\\output\\label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3761d60a-d254-4c0c-9820-2acc1c7e32a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['destination_port', 'flow_duration', 'total_fwd_packets',\n",
       "       'total_backward_packets', 'total_length_of_fwd_packets',\n",
       "       'total_length_of_bwd_packets', 'fwd_packet_length_max',\n",
       "       'fwd_packet_length_min', 'fwd_packet_length_mean',\n",
       "       'fwd_packet_length_std', 'bwd_packet_length_max',\n",
       "       'bwd_packet_length_min', 'bwd_packet_length_mean',\n",
       "       'bwd_packet_length_std', 'flow_bytes_per_sec',\n",
       "       'flow_packets_per_sec', 'flow_iat_mean', 'flow_iat_std',\n",
       "       'flow_iat_max', 'flow_iat_min', 'fwd_iat_total', 'fwd_iat_mean',\n",
       "       'fwd_iat_std', 'fwd_iat_max', 'fwd_iat_min', 'bwd_iat_total',\n",
       "       'bwd_iat_mean', 'bwd_iat_std', 'bwd_iat_max', 'bwd_iat_min',\n",
       "       'fwd_psh_flags', 'bwd_psh_flags', 'fwd_urg_flags', 'bwd_urg_flags',\n",
       "       'bwd_header_length', 'fwd_packets_per_sec', 'bwd_packets_per_sec',\n",
       "       'min_packet_length', 'max_packet_length', 'packet_length_mean',\n",
       "       'packet_length_std', 'packet_length_variance', 'fin_flag_count',\n",
       "       'syn_flag_count', 'rst_flag_count', 'psh_flag_count',\n",
       "       'ack_flag_count', 'urg_flag_count', 'cwe_flag_count',\n",
       "       'ece_flag_count', 'down_up_ratio', 'average_packet_size',\n",
       "       'avg_fwd_segment_size', 'avg_bwd_segment_size',\n",
       "       'fwd_header_length', 'fwd_avg_bytes_per_bulk',\n",
       "       'fwd_avg_packets_per_bulk', 'fwd_avg_bulk_rate',\n",
       "       'bwd_avg_bytes_per_bulk', 'bwd_avg_packets_per_bulk',\n",
       "       'bwd_avg_bulk_rate', 'subflow_fwd_packets', 'subflow_fwd_bytes',\n",
       "       'subflow_bwd_packets', 'subflow_bwd_bytes',\n",
       "       'init_win_bytes_forward', 'init_win_bytes_backward',\n",
       "       'act_data_pkt_fwd', 'min_seg_size_forward', 'active_mean',\n",
       "       'active_std', 'active_max', 'active_min', 'idle_mean', 'idle_std',\n",
       "       'idle_max', 'idle_min'], dtype='<U27')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1365862-c5a0-4272-b052-67f4724dd6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
